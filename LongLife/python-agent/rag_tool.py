import os
import glob
import pandas as pd
from langchain_core.documents import Document
from langchain_text_splitters import RecursiveCharacterTextSplitter
from langchain_chroma import Chroma
from langchain_google_genai import GoogleGenerativeAIEmbeddings

# ==========================================
# 1. ì„¤ì • (ê²½ë¡œ ë° ëª¨ë¸)
# ==========================================
PERSIST_DIR = "./chroma_db"
DATA_ROOT = "./data"

# ì„ë² ë”© ëª¨ë¸
embeddings = GoogleGenerativeAIEmbeddings(model="models/text-embedding-004")

# ì „ì—­ ë³€ìˆ˜
fitness_vector_store = None
diet_vector_store = None

# ==========================================
# 2. ì—‘ì…€ ë¡œë” (Pandas ê¸°ë°˜ ì»¤ìŠ¤í…€ ë¡œë”)
# ==========================================
def load_excel_as_documents(file_path: str):
    """
    ì—‘ì…€ íŒŒì¼ì„ ì½ì–´ì„œ ê° í–‰(Row)ì„ í•˜ë‚˜ì˜ ë¬¸ì„œ(Document)ë¡œ ë³€í™˜í•©ë‹ˆë‹¤.
    í˜•ì‹: "ì»¬ëŸ¼1: ê°’1, ì»¬ëŸ¼2: ê°’2 ..." 
    """
    try:
        df = pd.read_excel(file_path)
        # ë¹ˆ ë°ì´í„° ì œê±°
        df = df.dropna(how='all') 
        
        docs = []
        for index, row in df.iterrows():
            # ê° í–‰ì˜ ë°ì´í„°ë¥¼ "í‚¤: ê°’" í˜•íƒœì˜ ë¬¸ìì—´ë¡œ ë³€í™˜
            # ì˜ˆ: "ìš´ë™ëª…: ë²¤ì¹˜í”„ë ˆìŠ¤, ë¶€ìœ„: ê°€ìŠ´, ì„¤ëª…: ë¯¸ëŠ” ìš´ë™"
            row_text = ", ".join([f"{col}: {val}" for col, val in row.items() if pd.notna(val)])
            
            # ë©”íƒ€ë°ì´í„°ì— íŒŒì¼ëª…ê³¼ í–‰ ë²ˆí˜¸ ì €ì¥ (ë‚˜ì¤‘ì— ì¶œì²˜ ì°¾ê¸° ì¢‹ìŒ)
            metadata = {"source": os.path.basename(file_path), "row": index}
            
            docs.append(Document(page_content=row_text, metadata=metadata))
            
        return docs
    except Exception as e:
        print(f"   ğŸ”¥ ì—‘ì…€ ì½ê¸° ì‹¤íŒ¨: {file_path} - {e}")
        return []

# ==========================================
# 3. í•µì‹¬ ë¡œì§: DB ìƒì„±/ë¡œë“œ
# ==========================================
def get_or_create_vectorstore(category: str):
    target_folder = os.path.join(DATA_ROOT, category)
    collection_name = f"{category}_collection"
    
    print(f"ğŸ” [{category}] ì—‘ì…€ ë°ì´í„° DB í™•ì¸ ì¤‘...")

    vector_store = Chroma(
        persist_directory=PERSIST_DIR,
        embedding_function=embeddings,
        collection_name=collection_name
    )

    existing_count = len(vector_store.get()['ids'])
    if existing_count > 0:
        print(f"  âœ… [{category}] ê¸°ì¡´ DB ë¡œë“œ ì™„ë£Œ! (ë°ì´í„° ìˆ˜: {existing_count})")
        return vector_store

    print(f"  ğŸš€ [{category}] ë°ì´í„°ê°€ ë¹„ì–´ìˆìŠµë‹ˆë‹¤. ì—‘ì…€ ë¡œë”© ì‹œì‘...")
    
    # ì—‘ì…€ íŒŒì¼ ì°¾ê¸° (*.xlsx, *.xls)
    excel_files = glob.glob(os.path.join(target_folder, "*.xlsx")) + glob.glob(os.path.join(target_folder, "*.xls"))
    
    if not excel_files:
        print(f"  âš ï¸ ê²½ê³ : '{target_folder}' í´ë”ì— ì—‘ì…€ íŒŒì¼ì´ ì—†ìŠµë‹ˆë‹¤!")
        return vector_store

    documents = []
    for file in excel_files:
        docs = load_excel_as_documents(file)
        documents.extend(docs)
        print(f"   - ì½ìŒ: {os.path.basename(file)} ({len(docs)}ê°œ í–‰)")

    if documents:
        # ì—‘ì…€ì€ ì´ë¯¸ í–‰ ë‹¨ìœ„ë¡œ ì˜ë ¤ìˆì–´ì„œ chunk_sizeë¥¼ í¬ê²Œ ì¡ê±°ë‚˜ splitì„ ì•ˆ í•´ë„ ë˜ì§€ë§Œ,
        # ë‚´ìš©ì´ ì—„ì²­ ê¸´ ì…€ì´ ìˆì„ ìˆ˜ ìˆìœ¼ë‹ˆ ì•ˆì „ì¥ì¹˜ë¡œ ë‘ .
        splitter = RecursiveCharacterTextSplitter(chunk_size=1000, chunk_overlap=100)
        splits = splitter.split_documents(documents)
        
        vector_store.add_documents(splits)
        print(f"  ğŸ’¾ [{category}] DB êµ¬ì¶• ì™„ë£Œ! (ì´ {len(splits)}ê°œ ë°ì´í„° ì €ì¥)")
    
    return vector_store

# ==========================================
# 4. ì´ˆê¸°í™” ì‹¤í–‰
# ==========================================
def initialize_rags():
    global fitness_vector_store, diet_vector_store
    fitness_vector_store = get_or_create_vectorstore("fitness")
    diet_vector_store = get_or_create_vectorstore("diet")

# ==========================================
# 5. Agentìš© ê²€ìƒ‰ ë„êµ¬
# ==========================================
def search_fitness_db(query: str) -> str:
    """[ìš´ë™/í—¬ìŠ¤] ì§ˆë¬¸ ì‹œ ì‚¬ìš©. ì—‘ì…€ DBì—ì„œ ìš´ë™ë²•, ìì„¸ ë“±ì„ ê²€ìƒ‰."""
    if not fitness_vector_store: return "ìš´ë™ ì§€ì‹ DB ì¤€ë¹„ ì•ˆë¨."
    results = fitness_vector_store.similarity_search(query, k=3)
    return "[ìš´ë™ ê²€ìƒ‰ ê²°ê³¼]\n" + "\n".join([f"- {doc.page_content}" for doc in results])

def search_diet_db(query: str) -> str:
    """[ì‹ë‹¨/ì˜ì–‘] ì§ˆë¬¸ ì‹œ ì‚¬ìš©. ì—‘ì…€ DBì—ì„œ ì¹¼ë¡œë¦¬, ì‹ë‹¨í‘œ ë“±ì„ ê²€ìƒ‰."""
    if not diet_vector_store: return "ì‹ë‹¨ ì§€ì‹ DB ì¤€ë¹„ ì•ˆë¨."
    results = diet_vector_store.similarity_search(query, k=3)
    return "[ì‹ë‹¨ ê²€ìƒ‰ ê²°ê³¼]\n" + "\n".join([f"- {doc.page_content}" for doc in results])

# ìë™ ì‹¤í–‰
initialize_rags()